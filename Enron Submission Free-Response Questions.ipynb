{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#P5 Enron Fraud Detectors using Enron Emails and Financial Data.\n",
    "by Alexey Chesnok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]*\n",
    "\n",
    "The goal of the project to analyze [Enron Email Dataset](https://www.cs.cmu.edu/~./enron/) using predictive mashine learning techniques to try and identify individuals who might have been involved into Enron Fraud. Data set already contains 18 records labeled as \"POI\" (Person of Interest) - individuals who were either indicted, settled without admitting guilt, or testified in exchange for immunity. My task is pinpoint potential additional persons of interest, using their financial information from the dataset and email interactions with existing POIs. \n",
    "Enron Email Dataset consists of 146 records with 21 features (14 financial, 6 email message features and 1 predefined poi label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Alexey\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn import cross_validation\n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import tester\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select features\n",
    "financial_features = ['salary', \n",
    "                      'deferral_payments', \n",
    "                      'total_payments', \n",
    "                      'loan_advances', \n",
    "                      'bonus', \n",
    "                      'restricted_stock_deferred', \n",
    "                      'deferred_income', \n",
    "                      'total_stock_value', \n",
    "                      'expenses', \n",
    "                      'exercised_stock_options', \n",
    "                      'other', \n",
    "                      'long_term_incentive', \n",
    "                      'restricted_stock', \n",
    "                      'director_fees']\n",
    "\n",
    "email_features = ['to_messages', \n",
    "                 'email_address', \n",
    "                 'from_poi_to_this_person', \n",
    "                 'from_messages', \n",
    "                 'from_this_person_to_poi', \n",
    "                 'shared_receipt_with_poi'] \n",
    "\n",
    "features_list = email_features + financial_features\n",
    "features_list.insert(0, 'poi')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'to_messages', 'email_address', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees']\n"
     ]
    }
   ],
   "source": [
    "print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant number of features missing values, also predefined POIs have no entries for director_fees, restricted_stock_deferred, this renders both features irrelevant for further investigations, and \"email_address\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLEN PHILLIP K',\n",
       " 'BADUM JAMES P',\n",
       " 'BANNANTINE JAMES M',\n",
       " 'BAXTER JOHN C',\n",
       " 'BAY FRANKLIN R',\n",
       " 'BAZELIDES PHILIP J',\n",
       " 'BECK SALLY W',\n",
       " 'BELDEN TIMOTHY N',\n",
       " 'BELFER ROBERT',\n",
       " 'BERBERIAN DAVID',\n",
       " 'BERGSIEKER RICHARD P',\n",
       " 'BHATNAGAR SANJAY',\n",
       " 'BIBI PHILIPPE A',\n",
       " 'BLACHMAN JEREMY M',\n",
       " 'BLAKE JR. NORMAN P',\n",
       " 'BOWEN JR RAYMOND M',\n",
       " 'BROWN MICHAEL',\n",
       " 'BUCHANAN HAROLD G',\n",
       " 'BUTTS ROBERT H',\n",
       " 'BUY RICHARD B',\n",
       " 'CALGER CHRISTOPHER F',\n",
       " 'CARTER REBECCA C',\n",
       " 'CAUSEY RICHARD A',\n",
       " 'CHAN RONNIE',\n",
       " 'CHRISTODOULOU DIOMEDES',\n",
       " 'CLINE KENNETH W',\n",
       " 'COLWELL WESLEY',\n",
       " 'CORDES WILLIAM R',\n",
       " 'COX DAVID',\n",
       " 'CUMBERLAND MICHAEL S',\n",
       " 'DEFFNER JOSEPH M',\n",
       " 'DELAINEY DAVID W',\n",
       " 'DERRICK JR. JAMES V',\n",
       " 'DETMERING TIMOTHY J',\n",
       " 'DIETRICH JANET R',\n",
       " 'DIMICHELE RICHARD G',\n",
       " 'DODSON KEITH',\n",
       " 'DONAHUE JR JEFFREY M',\n",
       " 'DUNCAN JOHN H',\n",
       " 'DURAN WILLIAM D',\n",
       " 'ECHOLS JOHN B',\n",
       " 'ELLIOTT STEVEN',\n",
       " 'FALLON JAMES B',\n",
       " 'FASTOW ANDREW S',\n",
       " 'FITZGERALD JAY L',\n",
       " 'FOWLER PEGGY',\n",
       " 'FOY JOE',\n",
       " 'FREVERT MARK A',\n",
       " 'FUGH JOHN L',\n",
       " 'GAHN ROBERT S',\n",
       " 'GARLAND C KEVIN',\n",
       " 'GATHMANN WILLIAM D',\n",
       " 'GIBBS DANA R',\n",
       " 'GILLIS JOHN',\n",
       " 'GLISAN JR BEN F',\n",
       " 'GOLD JOSEPH',\n",
       " 'GRAMM WENDY L',\n",
       " 'GRAY RODNEY',\n",
       " 'HAEDICKE MARK E',\n",
       " 'HANNON KEVIN P',\n",
       " 'HAUG DAVID L',\n",
       " 'HAYES ROBERT E',\n",
       " 'HAYSLETT RODERICK J',\n",
       " 'HERMANN ROBERT J',\n",
       " 'HICKERSON GARY J',\n",
       " 'HIRKO JOSEPH',\n",
       " 'HORTON STANLEY C',\n",
       " 'HUGHES JAMES A',\n",
       " 'HUMPHREY GENE E',\n",
       " 'IZZO LAWRENCE L',\n",
       " 'JACKSON CHARLENE R',\n",
       " 'JAEDICKE ROBERT',\n",
       " 'KAMINSKI WINCENTY J',\n",
       " 'KEAN STEVEN J',\n",
       " 'KISHKILL JOSEPH G',\n",
       " 'KITCHEN LOUISE',\n",
       " 'KOENIG MARK E',\n",
       " 'KOPPER MICHAEL J',\n",
       " 'LAVORATO JOHN J',\n",
       " 'LAY KENNETH L',\n",
       " 'LEFF DANIEL P',\n",
       " 'LEMAISTRE CHARLES',\n",
       " 'LEWIS RICHARD',\n",
       " 'LINDHOLM TOD A',\n",
       " 'LOCKHART EUGENE E',\n",
       " 'LOWRY CHARLES P',\n",
       " 'MARTIN AMANDA K',\n",
       " 'MCCARTY DANNY J',\n",
       " 'MCCLELLAN GEORGE',\n",
       " 'MCCONNELL MICHAEL S',\n",
       " 'MCDONALD REBECCA',\n",
       " 'MCMAHON JEFFREY',\n",
       " 'MENDELSOHN JOHN',\n",
       " 'METTS MARK',\n",
       " 'MEYER JEROME J',\n",
       " 'MEYER ROCKFORD G',\n",
       " 'MORAN MICHAEL P',\n",
       " 'MORDAUNT KRISTINA M',\n",
       " 'MULLER MARK S',\n",
       " 'MURRAY JULIA H',\n",
       " 'NOLES JAMES L',\n",
       " 'OLSON CINDY K',\n",
       " 'OVERDYKE JR JERE C',\n",
       " 'PAI LOU L',\n",
       " 'PEREIRA PAULO V. FERRAZ',\n",
       " 'PICKERING MARK R',\n",
       " 'PIPER GREGORY F',\n",
       " 'PIRO JIM',\n",
       " 'POWERS WILLIAM',\n",
       " 'PRENTICE JAMES',\n",
       " 'REDMOND BRIAN L',\n",
       " 'REYNOLDS LAWRENCE',\n",
       " 'RICE KENNETH D',\n",
       " 'RIEKER PAULA H',\n",
       " 'SAVAGE FRANK',\n",
       " 'SCRIMSHAW MATTHEW',\n",
       " 'SHANKMAN JEFFREY A',\n",
       " 'SHAPIRO RICHARD S',\n",
       " 'SHARP VICTORIA T',\n",
       " 'SHELBY REX',\n",
       " 'SHERRICK JEFFREY B',\n",
       " 'SHERRIFF JOHN R',\n",
       " 'SKILLING JEFFREY K',\n",
       " 'STABLER FRANK',\n",
       " 'SULLIVAN-SHAKLOVITZ COLLEEN',\n",
       " 'SUNDE MARTIN',\n",
       " 'TAYLOR MITCHELL S',\n",
       " 'THE TRAVEL AGENCY IN THE PARK',\n",
       " 'THORN TERENCE H',\n",
       " 'TILNEY ELIZABETH A',\n",
       " 'TOTAL',\n",
       " 'UMANOFF ADAM S',\n",
       " 'URQUHART JOHN A',\n",
       " 'WAKEHAM JOHN',\n",
       " 'WALLS JR ROBERT H',\n",
       " 'WALTERS GARETH W',\n",
       " 'WASAFF GEORGE',\n",
       " 'WESTFAHL RICHARD K',\n",
       " 'WHALEY DAVID A',\n",
       " 'WHALLEY LAWRENCE G',\n",
       " 'WHITE JR THOMAS E',\n",
       " 'WINOKUR JR. HERBERT S',\n",
       " 'WODRASKA JOHN',\n",
       " 'WROBEL BRUCE',\n",
       " 'YEAGER F SCOTT',\n",
       " 'YEAP SOON']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transpond dataframe\n",
    "data_dict = pd.DataFrame.from_dict(data_dict)\n",
    "#reorder features\n",
    "data_dict = data_dict.T\n",
    "data_dict = data_dict[features_list]\n",
    "list(data_dict.index.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = data_dict.replace('NaN', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "poi                          146 non-null bool\n",
      "to_messages                  86 non-null float64\n",
      "email_address                111 non-null object\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "salary                       95 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "other                        93 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 24.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print data_dict.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, BELDEN TIMOTHY N to YEAGER F SCOTT\n",
      "Data columns (total 21 columns):\n",
      "poi                          18 non-null bool\n",
      "to_messages                  14 non-null float64\n",
      "email_address                18 non-null object\n",
      "from_poi_to_this_person      14 non-null float64\n",
      "from_messages                14 non-null float64\n",
      "from_this_person_to_poi      14 non-null float64\n",
      "shared_receipt_with_poi      14 non-null float64\n",
      "salary                       17 non-null float64\n",
      "deferral_payments            5 non-null float64\n",
      "total_payments               18 non-null float64\n",
      "loan_advances                1 non-null float64\n",
      "bonus                        16 non-null float64\n",
      "restricted_stock_deferred    0 non-null float64\n",
      "deferred_income              11 non-null float64\n",
      "total_stock_value            18 non-null float64\n",
      "expenses                     18 non-null float64\n",
      "exercised_stock_options      12 non-null float64\n",
      "other                        18 non-null float64\n",
      "long_term_incentive          12 non-null float64\n",
      "restricted_stock             17 non-null float64\n",
      "director_fees                0 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 3.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_dict_poi = data_dict.loc[data_dict['poi'] == True]\n",
    "print data_dict_poi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCKHART EUGENE E                20\n",
      "GRAMM WENDY L                    18\n",
      "WROBEL BRUCE                     18\n",
      "WHALEY DAVID A                   18\n",
      "THE TRAVEL AGENCY IN THE PARK    18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print data_dict.isnull().sum(axis=1).sort_values(ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have also removed record \"THE TRAVEL AGENCY IN THE PARK\" - not people, and \"LOCKHART EUGENE E\" - missing values for all features, and therefore useless for investigation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PlotHelper(feature_1, feature_2):\n",
    "    sns.FacetGrid(data_dict, hue=\"poi\").map(plt.scatter, feature_1, feature_2).add_legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(PlotHelper('total_payments', 'total_stock_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREVERT MARK A\n",
      "LAY KENNETH L\n",
      "SKILLING JEFFREY K\n",
      "TOTAL\n"
     ]
    }
   ],
   "source": [
    "for index, row in data_dict.iterrows():\n",
    "    if row[\"salary\"] != 'NaN' and row[\"salary\"] != 'NaN' and row[\"salary\"]>1000000 and row[\"salary\"]>400000:\n",
    "       print index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TOTAL'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['total_payments'].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several outliers in financial features were FREVERT MARK A, LAY KENNETH L, SKILLING JEFFREY K, and TOTAL. \"Total\" is a spread feature to be removed, the rest are POIs to be kept for further investigation. I have also removed features \"email_address\" and director_fees with restricted_stock_deferred - since they didn't have any entries for POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean up\n",
    "data_dict = data_dict.drop(['TOTAL', 'THE TRAVEL AGENCY IN THE PARK','LOCKHART EUGENE E'])\n",
    "#remove useless (email address, director_fees restricted_stock_deferred)\n",
    "del data_dict['email_address']\n",
    "del data_dict['director_fees']\n",
    "del data_dict['restricted_stock_deferred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2) What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]*\n",
    "\n",
    "\n",
    "I have generated 2 additional email features to the list \"proportion_to_poi\" (proportion of emails sent by the person to poi to total email sent by the person) and \"proportion_from_poi\" (proportion of emails sent to the person by poi to total email sent to the person) to track level of interaction with known persons of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict['proportion_to_poi'] = data_dict['from_this_person_to_poi']/data_dict['from_messages']\n",
    "data_dict['proportion_from_poi'] = data_dict['from_poi_to_this_person']/data_dict['to_messages']\n",
    "data_dict = data_dict.replace('inf', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict.T\n",
    "my_dataset.fillna(value=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = features_list + ['proportion_to_poi', 'proportion_from_poi']\n",
    "features_list = [e for e in features_list if e not in ('email_address', 'director_fees', 'restricted_stock_deferred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'proportion_to_poi', 'proportion_from_poi']\n"
     ]
    }
   ],
   "source": [
    "print features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried using simple column Correlation with POI, Lasso Regression and then univariate feature selection tool SelectKBest, to identify best performing features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poi                        1.000000\n",
      "to_messages                0.058954\n",
      "from_poi_to_this_person    0.167722\n",
      "from_messages             -0.074308\n",
      "from_this_person_to_poi    0.112940\n",
      "shared_receipt_with_poi    0.228313\n",
      "salary                     0.264976\n",
      "deferral_payments         -0.098428\n",
      "total_payments             0.230102\n",
      "loan_advances              0.999851\n",
      "bonus                      0.302384\n",
      "deferred_income           -0.265698\n",
      "total_stock_value          0.366462\n",
      "expenses                   0.060292\n",
      "exercised_stock_options    0.503551\n",
      "other                      0.120270\n",
      "long_term_incentive        0.254723\n",
      "restricted_stock           0.224814\n",
      "proportion_to_poi          0.339938\n",
      "proportion_from_poi        0.104406\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#correlations = zip(features_list[1:], data_dict.corrwith(data_dict['poi']))\n",
    "#print(correlations)\n",
    "#sorted(correlations, key = lambda x: x[1], reverse=True)\n",
    "print data_dict.corrwith(data_dict['poi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with correlations above 0.3\n",
      "['poi', 'loan_advances', 'exercised_stock_options', 'total_stock_value', 'bonus', 'proportion_to_poi']\n"
     ]
    }
   ],
   "source": [
    "#Select features with correlation above 0.3\n",
    "best_correlations_list = ['poi',\n",
    "                          'loan_advances',\n",
    "                          'exercised_stock_options',\n",
    "                          'total_stock_value',\n",
    "                          'bonus',\n",
    "                          'proportion_to_poi']\n",
    "print \"Features with correlations above 0.3\"\n",
    "print best_correlations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso Regression features:\n",
      "['poi', 'to_messages', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "#features = selector.fit_transform(features, labels)\n",
    "regression = Lasso()\n",
    "regression.fit(features, labels)\n",
    "coeficients = zip(features_list[1:],regression.coef_ != 0)\n",
    "best_coefs = sorted(coeficients, key = lambda x: x[1])\n",
    "#print best_coefs\n",
    "best_lasso_list = list(map(lambda x: x[0], best_coefs))\n",
    "best_lasso_list = [\"poi\"] + [e for e in best_lasso_list if e not in ('proportion_to_poi', 'from_poi_to_this_person', 'proportion_from_poi')]\n",
    "print(\"Best Lasso Regression features:\")\n",
    "print best_lasso_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several testing rounds top 5 SelectKBest features ended up to be included into the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest feature scores:\n",
      "Best SelectKBest features:\n",
      "['poi', 'exercised_stock_options', 'total_stock_value', 'bonus', 'salary', 'proportion_to_poi']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "k=5\n",
    "selector = SelectKBest(f_classif, k)\n",
    "selector.fit_transform(features, labels)\n",
    "print(\"SelectKBest feature scores:\")\n",
    "scores = zip(features_list[1:],selector.scores_)\n",
    "#scores = zip(features_list[1:],-np.log10(selector.pvalues_))\n",
    "sorted_scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "#print sorted_scores\n",
    "best_kbest_list = [\"poi\"] + list(map(lambda x: x[0], sorted_scores))[0:k]\n",
    "print(\"Best SelectKBest features:\")\n",
    "print best_kbest_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting 5 best performing features I have used scaling to normalize selected features for using them in Support Vector Machines Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, best_kbest_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = featureFormat(my_dataset, best_correlations_list, sort_keys = True)\n",
    "#labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = featureFormat(my_dataset, best_lasso_list, sort_keys = True)\n",
    "#labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "#labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print labels, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3. What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]*\n",
    "\n",
    "I have tryed Naive Bayers and Support Vector Machines algorithms. SVM Initially had better results especiall after parameter tuning with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes model\n",
      "accuracy: 0.849056603774\n",
      "precision: 0.375\n",
      "recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_n = GaussianNB()\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "clf_n.fit(features_train, labels_train)\n",
    "pred = clf_n.predict(features_test)\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "rec = recall_score(labels_test, pred)\n",
    "prec = precision_score(labels_test, pred)\n",
    "\n",
    "print \"Naive bayes model\"\n",
    "print \"accuracy:\", acc\n",
    "print \"precision:\", prec\n",
    "print \"recall:\", rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "accuracy:  0.905660377358\n",
      "precision:  0.666666666667\n",
      "recall:  0.333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=1)\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "recall = recall_score(labels_test, pred)\n",
    "precision = precision_score(labels_test, pred)\n",
    "\n",
    "print \"SVM\"\n",
    "print \"accuracy: \", accuracy\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4. What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]*\n",
    "\n",
    "Parameter tuning allows to intify parameter values for the best algorithm performance. Without tuning optimal algorithm configuration might be missed. I have uses GridSearchCV function to identify best performing parameters for Support Vector Machines, tuning C, gamma and kernel parameters. Naive Bayes algorithm doesn't have any parameters to tune.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "def param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    kernels = ['linear', 'rbf']\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel' : kernels }\n",
    "    grid_search = GridSearchCV(svm.SVC(), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print param_selection(features, labels, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5. What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]*\n",
    "\n",
    "Model validation allows independent testing of the algorithm. I have used KFold validation technique to split, shuffling data to minimize impact order of records on training portion of the dataset. Updated average evaluation metrics for Support Vector Machines model are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "accuracy:  0.855494505495\n",
      "precision:  0.1\n",
      "recall:  0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Alexey\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(len(labels), n_folds=10, shuffle = True)\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=1)\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "for train_indices, test_indices in kf:\n",
    "    features_train = [features[ii] for ii in train_indices]\n",
    "    features_test = [features[ii] for ii in test_indices]\n",
    "    labels_train = [labels[ii] for ii in train_indices]\n",
    "    labels_test = [labels[ii] for ii in test_indices]\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    accuracy.append(accuracy_score(labels_test, pred))\n",
    "    recall.append(recall_score(labels_test, pred))\n",
    "    precision.append(precision_score(labels_test, pred))\n",
    "\n",
    "print \"SVM\"\n",
    "print \"accuracy: \", np.average(accuracy)\n",
    "print \"precision: \", np.average(precision)\n",
    "print \"recall: \", np.average(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "accuracy:  0.862637362637\n",
      "precision:  0.383333333333\n",
      "recall:  0.333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(len(labels), n_folds=10, shuffle = True)\n",
    "clf = GaussianNB()\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "for train_indices, test_indices in kf:\n",
    "    features_train = [features[ii] for ii in train_indices]\n",
    "    features_test = [features[ii] for ii in test_indices]\n",
    "    labels_train = [labels[ii] for ii in train_indices]\n",
    "    labels_test = [labels[ii] for ii in test_indices]\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    accuracy.append(accuracy_score(labels_test, pred))\n",
    "    recall.append(recall_score(labels_test, pred))\n",
    "    precision.append(precision_score(labels_test, pred))\n",
    "\n",
    "print \"Naive Bayes\"\n",
    "print \"accuracy: \", np.average(accuracy)\n",
    "print \"precision: \", np.average(precision)\n",
    "print \"recall: \", np.average(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*6. Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]*\n",
    "\n",
    "For model evaluation I have chosen following metrics:\n",
    "Accuracy - proportion of cases when predicted POI status matched actual POI status, or overall ability of the algorithm to predict outcome wether it is POI or non-POI\n",
    "Recall - ability of algorithm to identify all possible POIs.\n",
    "Precision - ability of algorithm not to lable POIs as non-POI\n",
    "After crossvalidating both models with Kfold Naive Bayes performed consistently better than SVM on all 3 metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
