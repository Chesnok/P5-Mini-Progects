{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#P5 Enron Fraud Detectors using Enron Emails and Financial Data.\n",
    "by Alexey Chesnok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]*\n",
    "\n",
    "The goal of the project to analyze [Enron Email Dataset](https://www.cs.cmu.edu/~./enron/) using predictive mashine learning techniques to try and identify individuals who might have been involved into Enron Fraud. Data set already contains 18 records labeled as \"POI\" (Person of Interest) - individuals who were either indicted, settled without admitting guilt, or testified in exchange for immunity. My task is pinpoint potential additional persons of interest, using their financial information from the dataset and email interactions with existing POIs. \n",
    "Enron Email Dataset consists of 146 records with 21 features (14 financial, 6 email message features and 1 predefined poi label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Alexey\\Anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn import cross_validation\n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import tester\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select features\n",
    "financial_features = ['salary', \n",
    "                      'deferral_payments', \n",
    "                      'total_payments', \n",
    "                      'loan_advances', \n",
    "                      'bonus', \n",
    "                      'restricted_stock_deferred', \n",
    "                      'deferred_income', \n",
    "                      'total_stock_value', \n",
    "                      'expenses', \n",
    "                      'exercised_stock_options', \n",
    "                      'other', \n",
    "                      'long_term_incentive', \n",
    "                      'restricted_stock', \n",
    "                      'director_fees']\n",
    "\n",
    "email_features = ['to_messages', \n",
    "                 'email_address', \n",
    "                 'from_poi_to_this_person', \n",
    "                 'from_messages', \n",
    "                 'from_this_person_to_poi', \n",
    "                 'shared_receipt_with_poi'] \n",
    "\n",
    "features_list = email_features + financial_features\n",
    "features_list.insert(0, 'poi')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'to_messages', 'email_address', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees']\n"
     ]
    }
   ],
   "source": [
    "print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Transpond dataframe\n",
    "data_dict = pd.DataFrame.from_dict(data_dict)\n",
    "#reorder features\n",
    "data_dict = data_dict.T\n",
    "data_dict = data_dict[features_list]\n",
    "list(data_dict.index.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = data_dict.replace('NaN', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant number of features missing values, also predefined POIs have no entries for director_fees, restricted_stock_deferred, this renders both features irrelevant for further investigations, and \"email_address\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data_dict.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, BELDEN TIMOTHY N to YEAGER F SCOTT\n",
      "Data columns (total 21 columns):\n",
      "poi                          18 non-null bool\n",
      "to_messages                  14 non-null float64\n",
      "email_address                18 non-null object\n",
      "from_poi_to_this_person      14 non-null float64\n",
      "from_messages                14 non-null float64\n",
      "from_this_person_to_poi      14 non-null float64\n",
      "shared_receipt_with_poi      14 non-null float64\n",
      "salary                       17 non-null float64\n",
      "deferral_payments            5 non-null float64\n",
      "total_payments               18 non-null float64\n",
      "loan_advances                1 non-null float64\n",
      "bonus                        16 non-null float64\n",
      "restricted_stock_deferred    0 non-null float64\n",
      "deferred_income              11 non-null float64\n",
      "total_stock_value            18 non-null float64\n",
      "expenses                     18 non-null float64\n",
      "exercised_stock_options      12 non-null float64\n",
      "other                        18 non-null float64\n",
      "long_term_incentive          12 non-null float64\n",
      "restricted_stock             17 non-null float64\n",
      "director_fees                0 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 3.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_dict_poi = data_dict.loc[data_dict['poi'] == True]\n",
    "print data_dict_poi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCKHART EUGENE E                20\n",
      "GRAMM WENDY L                    18\n",
      "WROBEL BRUCE                     18\n",
      "WHALEY DAVID A                   18\n",
      "THE TRAVEL AGENCY IN THE PARK    18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print data_dict.isnull().sum(axis=1).sort_values(ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have also removed record \"THE TRAVEL AGENCY IN THE PARK\" - not people, and \"LOCKHART EUGENE E\" - missing values for all features, and therefore useless for investigation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PlotHelper(feature_1, feature_2):\n",
    "    sns.FacetGrid(data_dict, hue=\"poi\").map(plt.scatter, feature_1, feature_2).add_legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(PlotHelper('total_payments', 'total_stock_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREVERT MARK A\n",
      "LAY KENNETH L\n",
      "SKILLING JEFFREY K\n",
      "TOTAL\n"
     ]
    }
   ],
   "source": [
    "for index, row in data_dict.iterrows():\n",
    "    if row[\"salary\"] != 'NaN' and row[\"salary\"] != 'NaN' and row[\"salary\"]>1000000 and row[\"salary\"]>400000:\n",
    "       print index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TOTAL'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['total_payments'].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several outliers in financial features were FREVERT MARK A, LAY KENNETH L, SKILLING JEFFREY K, and TOTAL. \"Total\" is a spread feature to be removed, the rest are POIs to be kept for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean up\n",
    "data_dict = data_dict.drop(['TOTAL', 'THE TRAVEL AGENCY IN THE PARK','LOCKHART EUGENE E'])\n",
    "#remove useless (email address)\n",
    "#del data_dict['email_address']\n",
    "#del data_dict['director_fees']\n",
    "#del data_dict['restricted_stock_deferred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove useless (email address)\n",
    "del data_dict['email_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2) What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]*\n",
    "\n",
    "\n",
    "I have generated 2 additional email featurs to the list \"proportion_to_poi\" (proportion of emails sent by the person to poi to total email sent by the person) and \"proportion_from_poi\" (proportion of emails sent to the person by poi to total email sent to the person) to track level of interaction with known persons of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict['proportion_to_poi'] = data_dict['from_this_person_to_poi']/data_dict['from_messages']\n",
    "data_dict['proportion_from_poi'] = data_dict['from_poi_to_this_person']/data_dict['to_messages']\n",
    "data_dict = data_dict.replace('inf', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict.T\n",
    "my_dataset.fillna(value=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = features_list + ['proportion_to_poi', 'proportion_from_poi']\n",
    "features_list = [e for e in features_list if e not in ('email_address')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poi                          1.000000\n",
       "to_messages                  0.058954\n",
       "from_poi_to_this_person      0.167722\n",
       "from_messages               -0.074308\n",
       "from_this_person_to_poi      0.112940\n",
       "shared_receipt_with_poi      0.228313\n",
       "salary                       0.264976\n",
       "deferral_payments           -0.098428\n",
       "total_payments               0.230102\n",
       "loan_advances                0.999851\n",
       "bonus                        0.302384\n",
       "restricted_stock_deferred         NaN\n",
       "deferred_income             -0.265698\n",
       "total_stock_value            0.366462\n",
       "expenses                     0.060292\n",
       "exercised_stock_options      0.503551\n",
       "other                        0.120270\n",
       "long_term_incentive          0.254723\n",
       "restricted_stock             0.224814\n",
       "director_fees                     NaN\n",
       "proportion_to_poi            0.339938\n",
       "proportion_from_poi          0.104406\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlations = zip(features_list[1:], data_dict.corrwith(data_dict['poi']))\n",
    "#print(correlations)\n",
    "#sorted(correlations, key = lambda x: x[1], reverse=True)\n",
    "data_dict.corrwith(data_dict['poi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select features with correlation above 0.3\n",
    "best_correlations_list = ['poi',\n",
    "                          'loan_advances',\n",
    "                          'exercised_stock_options',\n",
    "                          'total_stock_value',\n",
    "                          'bonus',\n",
    "                          'proportion_to_poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following features ended up to be included into the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tied using Lasso Regression and then univariate feature selection tool SelectKBest, to identify best performing features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "#features = selector.fit_transform(features, labels)\n",
    "regression = Lasso()\n",
    "regression.fit(features, labels)\n",
    "coeficients = zip(features_list[1:],regression.coef_ != 0)\n",
    "best_coefs = sorted(coeficients, key = lambda x: x[1])\n",
    "print best_coefs\n",
    "best_lasso_list = list(map(lambda x: x[0], best_coefs))\n",
    "best_lasso_list = [\"poi\"] + [e for e in best_lasso_list if e not in ('proportion_to_poi', 'from_poi_to_this_person', 'proportion_from_poi')]\n",
    "print(\"Best Lasso Regression features:\")\n",
    "print best_lasso_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "k=5\n",
    "selector = SelectKBest(f_classif, k)\n",
    "selector.fit_transform(features, labels)\n",
    "print(\"SelectKBest feature scores:\")\n",
    "scores = zip(best_correlations_list[1:],selector.scores_)\n",
    "#scores = zip(features_list[1:],-np.log10(selector.pvalues_))\n",
    "sorted_scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "print sorted_scores\n",
    "best_kbest_list = [\"poi\"] + list(map(lambda x: x[0], sorted_scores))[0:k]\n",
    "print(\"Best SelectKBest features:\")\n",
    "print best_kbest_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting 10 best performing feature I have used scaling to normalize selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, best_correlations_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, best_kbest_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, best_lasso_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3. What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]*\n",
    "\n",
    "I have tryed Naive Vayers and SVM algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes model\n",
      "accuracy: 0.871794871795\n",
      "precision: 0.0\n",
      "recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_n = GaussianNB()\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "clf_n.fit(features_train, labels_train)\n",
    "pred = clf_n.predict(features_test)\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "rec = recall_score(labels_test, pred)\n",
    "prec = precision_score(labels_test, pred)\n",
    "\n",
    "print \"Naive bayes model\"\n",
    "print \"accuracy:\", acc\n",
    "print \"precision:\", prec\n",
    "print \"recall:\", rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "accuracy:  0.923076923077\n",
      "precision:  0.0\n",
      "recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=1)\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "recall = recall_score(labels_test, pred)\n",
    "precision = precision_score(labels_test, pred)\n",
    "\n",
    "print \"SVM\"\n",
    "print \"accuracy: \", accuracy\n",
    "print \"precision: \", precision\n",
    "print \"recall: \", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4. What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]*\n",
    "\n",
    "Parameter tuning allows to intify parameter values for the best algorithm performance. Without tuning optimal algorithm configuration might be missed. I have uses GridSearchCV function to identify best performing parameters for SVC, tuning C, gamma and kernel parameters. Naive Bayes algorithm doesn't have any parameters to tune.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "def param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    kernels = ['linear', 'rbf']\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel' : kernels }\n",
    "    grid_search = GridSearchCV(svm.SVC(), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print param_selection(features, labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5. What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]*\n",
    "\n",
    "Model validation allows independent testing of the algorithm. I have used KFold validation technique to split, shuffling data to minimize impact order of records on training portion of the dataset. Updated average evaluation metrics for SVM model are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "accuracy:  0.869230769231\n",
      "precision:  0.3\n",
      "recall:  0.183333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(len(labels), n_folds=10, shuffle = True)\n",
    "clf = svm.SVC(kernel='rbf', C=10, gamma=1)\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "for train_indices, test_indices in kf:\n",
    "    features_train = [features[ii] for ii in train_indices]\n",
    "    features_test = [features[ii] for ii in test_indices]\n",
    "    labels_train = [labels[ii] for ii in train_indices]\n",
    "    labels_test = [labels[ii] for ii in test_indices]\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    accuracy.append(accuracy_score(labels_test, pred))\n",
    "    recall.append(recall_score(labels_test, pred))\n",
    "    precision.append(precision_score(labels_test, pred))\n",
    "\n",
    "print \"SVM\"\n",
    "print \"accuracy: \", np.average(accuracy)\n",
    "print \"precision: \", np.average(precision)\n",
    "print \"recall: \", np.average(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "accuracy:  0.792307692308\n",
      "precision:  0.225\n",
      "recall:  0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(len(labels), n_folds=10, shuffle = True)\n",
    "clf = GaussianNB()\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "for train_indices, test_indices in kf:\n",
    "    features_train = [features[ii] for ii in train_indices]\n",
    "    features_test = [features[ii] for ii in test_indices]\n",
    "    labels_train = [labels[ii] for ii in train_indices]\n",
    "    labels_test = [labels[ii] for ii in test_indices]\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    accuracy.append(accuracy_score(labels_test, pred))\n",
    "    recall.append(recall_score(labels_test, pred))\n",
    "    precision.append(precision_score(labels_test, pred))\n",
    "\n",
    "print \"SVM\"\n",
    "print \"accuracy: \", np.average(accuracy)\n",
    "print \"precision: \", np.average(precision)\n",
    "print \"recall: \", np.average(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*6. Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]*\n",
    "\n",
    "I have chosen accuracy, recall and precision metrics for model evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
